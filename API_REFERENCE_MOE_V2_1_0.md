# Aethel MOE v2.1.0 - API Reference

**Version**: v2.1.0  
**Last Updated**: February 15, 2026

---

## Table of Contents

1. [MOE Orchestrator](#moe-orchestrator)
2. [Base Expert Interface](#base-expert-interface)
3. [Z3 Expert](#z3-expert)
4. [Sentinel Expert](#sentinel-expert)
5. [Guardian Expert](#guardian-expert)
6. [Gating Network](#gating-network)
7. [Consensus Engine](#consensus-engine)
8. [Visual Dashboard](#visual-dashboard)
9. [Expert Telemetry](#expert-telemetry)
10. [Training System](#training-system)
11. [Data Models](#data-models)

---

## MOE Orchestrator

Central coordinator that manages expert lifecycle and aggregates results.

### Class: `MOEOrchestrator`

**Location**: `aethel.moe.orchestrator`

#### Constructor

```python
MOEOrchestrator(
    enable_cache: bool = True,
    cache_ttl_seconds: int = 300,
    telemetry_db_path: str = ".aethel_moe/telemetry.db"
)
```

**Parameters**:
- `enable_cache` (bool): Enable verdict caching. Default: `True`
- `cache_ttl_seconds` (int): Cache TTL in seconds. Default: `300` (5 minutes)
- `telemetry_db_path` (str): Path to telemetry database. Default: `.aethel_moe/telemetry.db`

#### Methods

##### `register_expert(name: str, expert: BaseExpert) -> None`

Register a new expert with the orchestrator.

**Parameters**:
- `name` (str): Unique expert identifier
- `expert` (BaseExpert): Expert instance

**Raises**:
- `ValueError`: If expert with same name already registered

**Example**:
```python
orchestrator = MOEOrchestrator()
orchestrator.register_expert("Z3_Expert", Z3Expert())
```

##### `unregister_expert(name: str) -> None`

Unregister an expert from the orchestrator.

**Parameters**:
- `name` (str): Expert identifier

**Raises**:
- `ValueError`: If expert not found

##### `verify_transaction(intent: str, tx_id: str) -> MOEResult`

Main verification entry point.

**Parameters**:
- `intent` (str): Transaction intent code
- `tx_id` (str): Transaction identifier

**Returns**:
- `MOEResult`: Unified verification result

**Process**:
1. Extract features from intent
2. Route to appropriate experts via gating network
3. Execute experts in parallel
4. Aggregate results via consensus engine
5. Return unified verdict

**Example**:
```python
result = orchestrator.verify_transaction(
    intent="transfer(alice, bob, 100)",
    tx_id="tx_001"
)
print(f"Consensus: {result.consensus}")
print(f"Confidence: {result.overall_confidence:.2%}")
```

##### `get_expert_status() -> Dict[str, Any]`

Get current status of all registered experts.

**Returns**:
- `Dict[str, Any]`: Expert status information

**Example**:
```python
status = orchestrator.get_expert_status()
for expert_name, info in status.items():
    print(f"{expert_name}: {info['total_verifications']} verifications")
```

##### `get_statistics() -> Dict[str, Any]`

Get orchestrator statistics.

**Returns**:
- `Dict[str, Any]`: Statistics including cache hit rate, total verifications, etc.

##### `clear_cache() -> None`

Clear the verdict cache.

##### `reset_statistics() -> None`

Reset orchestrator statistics.

---

## Base Expert Interface

Abstract base class that all experts must implement.

### Class: `BaseExpert`

**Location**: `aethel.moe.base_expert`

#### Constructor

```python
BaseExpert(name: str)
```

**Parameters**:
- `name` (str): Expert identifier

#### Abstract Methods

##### `verify(intent: str, tx_id: str) -> ExpertVerdict`

Verify transaction intent and return verdict.

**Must be implemented by all expert subclasses.**

**Parameters**:
- `intent` (str): Transaction intent code
- `tx_id` (str): Transaction identifier

**Returns**:
- `ExpertVerdict`: Expert's verdict with confidence and reasoning

**Should complete within expert-specific timeout.**

#### Methods

##### `get_average_latency() -> float`

Get average latency across all verifications.

**Returns**:
- `float`: Average latency in milliseconds

##### `get_accuracy() -> float`

Get accuracy over last 1000 verifications.

**Returns**:
- `float`: Accuracy (0.0 to 1.0)

##### `update_accuracy(was_correct: bool) -> None`

Update accuracy history with ground truth.

**Parameters**:
- `was_correct` (bool): Whether the verdict was correct

---

## Z3 Expert

Mathematical logic specialist using Z3 theorem prover.

### Class: `Z3Expert`

**Location**: `aethel.moe.z3_expert`

**Inherits**: `BaseExpert`

#### Constructor

```python
Z3Expert(
    timeout_normal: int = 30,
    timeout_crisis: int = 5,
    max_variables: int = 100,
    max_constraints: int = 1000
)
```

**Parameters**:
- `timeout_normal` (int): Normal mode timeout in seconds. Default: `30`
- `timeout_crisis` (int): Crisis mode timeout in seconds. Default: `5`
- `max_variables` (int): Maximum variables per proof. Default: `100`
- `max_constraints` (int): Maximum constraints per proof. Default: `1000`

#### Methods

##### `verify(intent: str, tx_id: str) -> ExpertVerdict`

Verify mathematical logic and constraints.

**Checks**:
- Arithmetic operations (overflow, underflow)
- Logical invariants
- Mathematical constraints
- Symbolic execution paths

**Returns**:
- `ExpertVerdict`: Verdict with confidence based on proof complexity

**Example**:
```python
expert = Z3Expert()
verdict = expert.verify("x = 5; assert x > 0", "tx_001")
print(f"Verdict: {verdict.verdict}")
print(f"Confidence: {verdict.confidence:.2%}")
```

##### `set_crisis_mode(enabled: bool) -> None`

Toggle crisis mode (5s timeout).

**Parameters**:
- `enabled` (bool): Enable crisis mode

##### `is_crisis_mode() -> bool`

Check if crisis mode is enabled.

**Returns**:
- `bool`: True if crisis mode enabled

---

## Sentinel Expert

Security specialist for attack detection.

### Class: `SentinelExpert`

**Location**: `aethel.moe.sentinel_expert`

**Inherits**: `BaseExpert`

#### Constructor

```python
SentinelExpert(timeout_ms: int = 100)
```

**Parameters**:
- `timeout_ms` (int): Timeout in milliseconds. Default: `100`

#### Methods

##### `verify(intent: str, tx_id: str) -> ExpertVerdict`

Verify security properties and detect attacks.

**Checks**:
- Overflow vulnerabilities
- DoS attack patterns (infinite loops, resource exhaustion)
- Injection attacks
- Malicious intent (high entropy, obfuscation)
- Trojan patterns

**Returns**:
- `ExpertVerdict`: Verdict with confidence based on entropy score

**Example**:
```python
expert = SentinelExpert()
verdict = expert.verify("while True: pass", "tx_001")
print(f"Verdict: {verdict.verdict}")  # REJECT
print(f"Reason: {verdict.reason}")    # Infinite loop detected
```

---

## Guardian Expert

Financial specialist for conservation verification.

### Class: `GuardianExpert`

**Location**: `aethel.moe.guardian_expert`

**Inherits**: `BaseExpert`

#### Constructor

```python
GuardianExpert(timeout_ms: int = 50)
```

**Parameters**:
- `timeout_ms` (int): Timeout in milliseconds. Default: `50`

#### Methods

##### `verify(intent: str, tx_id: str) -> ExpertVerdict`

Verify financial conservation laws.

**Checks**:
- Sum of inputs = Sum of outputs
- No funds created or destroyed
- Merkle tree integrity
- Double-spending prevention
- Account balance constraints

**Returns**:
- `ExpertVerdict`: Verdict with confidence based on conservation delta

**Example**:
```python
expert = GuardianExpert()
verdict = expert.verify("transfer(alice, bob, 100)", "tx_001")
print(f"Verdict: {verdict.verdict}")
print(f"Confidence: {verdict.confidence:.2%}")
```

---

## Gating Network

Intelligent routing system that determines which experts to activate.

### Class: `GatingNetwork`

**Location**: `aethel.moe.gating_network`

#### Constructor

```python
GatingNetwork()
```

#### Methods

##### `route(features: Dict[str, Any]) -> List[str]`

Determine which experts to activate based on intent features.

**Parameters**:
- `features` (Dict[str, Any]): Extracted features from transaction intent

**Returns**:
- `List[str]`: List of expert names to activate

**Routing Rules**:
- Financial transactions → Guardian Expert
- Arithmetic operations → Z3 Expert
- Loops/recursion → Sentinel Expert
- High complexity → Sentinel Expert
- Default: All experts

**Example**:
```python
gating = GatingNetwork()
features = {
    'has_transfers': True,
    'has_arithmetic': False,
    'has_loops': False,
    'complexity_score': 0.3
}
experts = gating.route(features)
print(f"Activated experts: {experts}")  # ['Guardian_Expert']
```

##### `get_recent_decisions(n: int = 10) -> List[Dict[str, Any]]`

Get recent routing decisions.

**Parameters**:
- `n` (int): Number of recent decisions. Default: `10`

**Returns**:
- `List[Dict[str, Any]]`: Recent routing decisions

##### `get_routing_stats() -> Dict[str, Any]`

Get routing statistics.

**Returns**:
- `Dict[str, Any]`: Statistics including activation rates per expert

---

## Consensus Engine

Verdict aggregation system.

### Class: `ConsensusEngine`

**Location**: `aethel.moe.consensus_engine`

#### Constructor

```python
ConsensusEngine(
    confidence_threshold: float = 0.7,
    uncertainty_threshold: float = 0.5
)
```

**Parameters**:
- `confidence_threshold` (float): Minimum confidence for approval. Default: `0.7`
- `uncertainty_threshold` (float): Below this = uncertain. Default: `0.5`

#### Methods

##### `aggregate(verdicts: List[ExpertVerdict]) -> MOEResult`

Aggregate expert verdicts into consensus.

**Parameters**:
- `verdicts` (List[ExpertVerdict]): Expert verdicts

**Returns**:
- `MOEResult`: Unified consensus result

**Consensus Rules**:
- If ANY expert rejects with high confidence (>0.7), REJECT
- If ALL experts approve with high confidence (>0.7), APPROVE
- If confidence mixed or low, mark as UNCERTAIN (human review)

**Example**:
```python
engine = ConsensusEngine()
verdicts = [
    ExpertVerdict("Z3_Expert", "APPROVE", 0.98, 25.3, None, None),
    ExpertVerdict("Sentinel_Expert", "APPROVE", 0.95, 12.1, None, None),
    ExpertVerdict("Guardian_Expert", "APPROVE", 1.0, 8.7, None, None)
]
result = engine.aggregate(verdicts)
print(f"Consensus: {result.consensus}")  # APPROVED
```

##### `set_confidence_threshold(threshold: float) -> None`

Set confidence threshold.

**Parameters**:
- `threshold` (float): New threshold (0.0 to 1.0)

**Raises**:
- `ValueError`: If threshold not in valid range

##### `set_uncertainty_threshold(threshold: float) -> None`

Set uncertainty threshold.

**Parameters**:
- `threshold` (float): New threshold (0.0 to 1.0)

**Raises**:
- `ValueError`: If threshold not in valid range

##### `get_config() -> Dict[str, float]`

Get current configuration.

**Returns**:
- `Dict[str, float]`: Configuration including thresholds

---

## Visual Dashboard

Console-based visual dashboard for real-time expert status.

### Class: `VisualDashboard`

**Location**: `aethel.moe.visual_dashboard`

#### Constructor

```python
VisualDashboard(
    expert_names: List[str] = None,
    enable_animation: bool = True
)
```

**Parameters**:
- `expert_names` (List[str]): Expert names to display. Default: `["Z3_Expert", "Sentinel_Expert", "Guardian_Expert"]`
- `enable_animation` (bool): Enable animation. Default: `True`

#### Methods

##### `start_verification() -> None`

Start verification (set all experts to PROCESSING).

##### `update_expert(expert_name: str, verdict: str, confidence: float, latency_ms: float) -> None`

Update expert status.

**Parameters**:
- `expert_name` (str): Expert identifier
- `verdict` (str): "APPROVE" or "REJECT"
- `confidence` (float): Confidence score (0.0 to 1.0)
- `latency_ms` (float): Latency in milliseconds

##### `complete_verification(consensus: str, overall_confidence: float) -> None`

Complete verification.

**Parameters**:
- `consensus` (str): "APPROVED", "REJECTED", or "UNCERTAIN"
- `overall_confidence` (float): Overall confidence (0.0 to 1.0)

##### `render() -> str`

Render dashboard to string.

**Returns**:
- `str`: Rendered dashboard

**Example**:
```python
dashboard = VisualDashboard()
dashboard.start_verification()
dashboard.update_expert("Z3_Expert", "APPROVE", 0.98, 25.3)
dashboard.update_expert("Sentinel_Expert", "APPROVE", 0.95, 12.1)
dashboard.update_expert("Guardian_Expert", "APPROVE", 1.0, 8.7)
dashboard.complete_verification("APPROVED", 0.98)
print(dashboard.render())
```

### Class: `DashboardManager`

Higher-level dashboard manager with automatic rendering.

#### Constructor

```python
DashboardManager(
    expert_names: List[str] = None,
    enable_animation: bool = True,
    auto_render: bool = True
)
```

**Parameters**:
- `expert_names` (List[str]): Expert names to display
- `enable_animation` (bool): Enable animation
- `auto_render` (bool): Automatically render on updates. Default: `True`

#### Methods

##### `start() -> None`

Start verification and render.

##### `update(expert_name: str, verdict: str, confidence: float, latency_ms: float) -> None`

Update expert and render.

##### `complete(consensus: str, overall_confidence: float) -> None`

Complete verification and render.

##### `animate() -> None`

Advance animation frame and render.

##### `clear() -> None`

Clear dashboard display.

---

## Expert Telemetry

Performance tracking system for experts.

### Class: `ExpertTelemetry`

**Location**: `aethel.moe.telemetry`

#### Constructor

```python
ExpertTelemetry(db_path: str = ".aethel_moe/telemetry.db")
```

**Parameters**:
- `db_path` (str): Path to telemetry database

#### Methods

##### `record(tx_id: str, verdicts: List[ExpertVerdict], consensus: MOEResult) -> None`

Record expert verdicts and consensus.

**Parameters**:
- `tx_id` (str): Transaction identifier
- `verdicts` (List[ExpertVerdict]): Expert verdicts
- `consensus` (MOEResult): Consensus result

##### `get_expert_stats(expert_name: str, time_window_seconds: int = 3600) -> Dict[str, Any]`

Get performance statistics for a specific expert.

**Parameters**:
- `expert_name` (str): Expert identifier
- `time_window_seconds` (int): Time window in seconds. Default: `3600` (1 hour)

**Returns**:
- `Dict[str, Any]`: Statistics including average latency, accuracy, confidence distribution

**Example**:
```python
telemetry = ExpertTelemetry()
stats = telemetry.get_expert_stats("Z3_Expert", time_window_seconds=3600)
print(f"Average latency: {stats['avg_latency_ms']:.2f}ms")
print(f"Accuracy: {stats['accuracy']:.2%}")
```

##### `export_prometheus() -> str`

Export metrics in Prometheus format.

**Returns**:
- `str`: Prometheus-formatted metrics

---

## Training System

System for collecting ground truth and improving expert accuracy.

### Class: `ExpertTrainingSystem`

**Location**: `aethel.moe.training`

#### Constructor

```python
ExpertTrainingSystem(db_path: str = ".aethel_moe/training.db")
```

**Parameters**:
- `db_path` (str): Path to training database

#### Methods

##### `record_ground_truth(tx_id: str, expert_name: str, verdict: str, confidence: float, actual_outcome: str) -> None`

Record ground truth for training.

**Parameters**:
- `tx_id` (str): Transaction identifier
- `expert_name` (str): Expert identifier
- `verdict` (str): Expert's verdict
- `confidence` (float): Expert's confidence
- `actual_outcome` (str): Actual outcome ("CORRECT" or "INCORRECT")

##### `calculate_accuracy(expert_name: str, window_size: int = 1000) -> Dict[str, Any]`

Calculate expert accuracy over rolling window.

**Parameters**:
- `expert_name` (str): Expert identifier
- `window_size` (int): Window size. Default: `1000`

**Returns**:
- `Dict[str, Any]`: Accuracy metrics including true positives, false positives, etc.

##### `adjust_confidence_threshold(expert_name: str, target_accuracy: float = 0.999) -> float`

Adjust expert confidence threshold based on historical accuracy.

**Parameters**:
- `expert_name` (str): Expert identifier
- `target_accuracy` (float): Target accuracy. Default: `0.999`

**Returns**:
- `float`: New confidence threshold

##### `register_model_version(expert_name: str, version: str, description: str) -> None`

Register a new expert model version for A/B testing.

**Parameters**:
- `expert_name` (str): Expert identifier
- `version` (str): Model version
- `description` (str): Version description

##### `compare_model_versions(expert_name: str, version1: str, version2: str) -> Dict[str, Any]`

Compare two model versions.

**Parameters**:
- `expert_name` (str): Expert identifier
- `version1` (str): First model version
- `version2` (str): Second model version

**Returns**:
- `Dict[str, Any]`: Comparison results including accuracy difference

---

## Data Models

### Class: `ExpertVerdict`

**Location**: `aethel.moe.data_models`

Expert's verdict on a transaction.

**Attributes**:
- `expert_name` (str): Expert identifier
- `verdict` (str): "APPROVE" or "REJECT"
- `confidence` (float): Confidence score (0.0 to 1.0)
- `latency_ms` (float): Verification latency in milliseconds
- `reason` (Optional[str]): Rejection reason (if rejected)
- `proof_trace` (Optional[Dict[str, Any]]): Proof trace for debugging

**Example**:
```python
verdict = ExpertVerdict(
    expert_name="Z3_Expert",
    verdict="APPROVE",
    confidence=0.98,
    latency_ms=25.3,
    reason=None,
    proof_trace={"steps": 5}
)
```

### Class: `MOEResult`

**Location**: `aethel.moe.data_models`

Unified MOE verification result.

**Attributes**:
- `transaction_id` (str): Transaction identifier
- `consensus` (str): "APPROVED", "REJECTED", or "UNCERTAIN"
- `overall_confidence` (float): Overall confidence (0.0 to 1.0)
- `expert_verdicts` (List[ExpertVerdict]): Individual expert verdicts
- `total_latency_ms` (float): Total verification latency
- `activated_experts` (List[str]): List of activated expert names

**Example**:
```python
result = MOEResult(
    transaction_id="tx_001",
    consensus="APPROVED",
    overall_confidence=0.98,
    expert_verdicts=[...],
    total_latency_ms=45.6,
    activated_experts=["Z3_Expert", "Sentinel_Expert", "Guardian_Expert"]
)
```

---

## Error Handling

All MOE components follow consistent error handling:

1. **Expert Failures**: Return low-confidence rejection verdict
2. **Timeouts**: Return rejection verdict with timeout reason
3. **Invalid Input**: Return rejection verdict with validation error
4. **System Errors**: Log error and fall back to existing layers

**Example**:
```python
try:
    result = orchestrator.verify_transaction(intent, tx_id)
except Exception as e:
    # MOE failure - fall back to existing layers
    logger.error(f"MOE failure: {e}")
    result = fallback_verification(intent, tx_id)
```

---

## Performance Considerations

### Verdict Caching

Enable caching for frequently verified patterns:

```python
orchestrator = MOEOrchestrator(
    enable_cache=True,
    cache_ttl_seconds=300  # 5 minutes
)
```

**Cache hit rate**: 93% in production

### Parallel Execution

Experts execute in parallel using `ThreadPoolExecutor`:

```python
# Automatic parallel execution
result = orchestrator.verify_transaction(intent, tx_id)
```

### Telemetry Overhead

Telemetry recording adds ~1ms overhead per verification. Disable for maximum performance:

```python
orchestrator = MOEOrchestrator(telemetry_db_path=None)
```

---

## Environment Variables

```bash
# Enable/disable MOE layer
AETHEL_MOE_ENABLED=true

# Expert timeouts
AETHEL_Z3_TIMEOUT_NORMAL=30000
AETHEL_Z3_TIMEOUT_CRISIS=5000
AETHEL_SENTINEL_TIMEOUT=100
AETHEL_GUARDIAN_TIMEOUT=50

# Consensus thresholds
AETHEL_CONSENSUS_CONFIDENCE_THRESHOLD=0.7
AETHEL_CONSENSUS_UNCERTAINTY_THRESHOLD=0.5

# Verdict caching
AETHEL_VERDICT_CACHE_ENABLED=true
AETHEL_VERDICT_CACHE_TTL=300

# Telemetry
AETHEL_TELEMETRY_DB_PATH=.aethel_moe/telemetry.db
```

---

**Author**: Kiro AI - Engenheiro-Chefe  
**Date**: February 15, 2026  
**Version**: v2.1.0 "The MOE Intelligence Layer"
