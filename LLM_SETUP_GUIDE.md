# ğŸ§  Guia de ConfiguraÃ§Ã£o de LLM - Aethel AI-Gate

**VersÃ£o**: v3.0  
**Atualizado**: Fevereiro 2026

---

## ğŸ¯ OpÃ§Ãµes DisponÃ­veis

A Aethel suporta **3 tipos** de integraÃ§Ã£o com LLMs:

### 1. LLM Local (Gratuito, Privado) ğŸ 
- **Custo**: $0 (apenas hardware)
- **Privacidade**: 100% (dados nÃ£o saem do servidor)
- **Ideal para**: Bancos, governo, dados sensÃ­veis

### 2. API Comercial (Gerenciado) â˜ï¸
- **Custo**: VariÃ¡vel (por uso)
- **Privacidade**: Depende do provedor
- **Ideal para**: Startups, desenvolvimento rÃ¡pido

### 3. HÃ­brido (Melhor dos 2 mundos) ğŸ”„
- **Custo**: Otimizado
- **Privacidade**: ConfigurÃ¡vel
- **Ideal para**: Empresas mÃ©dias/grandes

---

## ğŸ  OpÃ§Ã£o 1: LLM Local (Recomendado para ProduÃ§Ã£o)

### Passo 1: Instalar Ollama

**Windows**:
```bash
# Download do site oficial
https://ollama.ai/download

# Ou via winget
winget install Ollama.Ollama
```

**Linux/Mac**:
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

### Passo 2: Baixar Modelo

```bash
# Llama 3 (8B) - RÃ¡pido, bom para produÃ§Ã£o
ollama pull llama3

# Mistral (7B) - Alternativa rÃ¡pida
ollama pull mistral

# CodeLlama (13B) - Melhor para cÃ³digo
ollama pull codellama
```

### Passo 3: Configurar Aethel

```python
from aethel.ai import AIGate, LLMConfig

# ConfiguraÃ§Ã£o local
config = LLMConfig.local("ollama", model="llama3")

# Inicializar AI-Gate
gate = AIGate(config=config)

# Usar normalmente
result = gate.voice_to_code("Transfer $100 with 2% fee")
print(f"Verified: {result.verified}")
print(f"Code: {result.aethel_code}")
```

### Vantagens
âœ… **Custo zero** de API  
âœ… **Privacidade total** (dados nÃ£o saem do servidor)  
âœ… **Sem limites** de uso  
âœ… **Sem dependÃªncia** de terceiros  
âœ… **LatÃªncia baixa** (local)

### Desvantagens
âŒ Requer hardware (GPU recomendada)  
âŒ Qualidade pode ser menor que GPT-4  
âŒ VocÃª gerencia a infraestrutura

### Requisitos de Hardware

**MÃ­nimo** (Llama 3 8B):
- RAM: 16 GB
- GPU: 8 GB VRAM (ou CPU)
- Disco: 10 GB

**Recomendado** (Llama 3 70B):
- RAM: 64 GB
- GPU: 40 GB VRAM (A100)
- Disco: 50 GB

---

## â˜ï¸ OpÃ§Ã£o 2: API Comercial

### OpenAI (GPT-4)

```python
from aethel.ai import AIGate, LLMConfig

# ConfiguraÃ§Ã£o OpenAI
config = LLMConfig.api(
    provider="openai",
    api_key="sk-...",  # Sua chave
    model="gpt-4-turbo"
)

gate = AIGate(config=config)
```

**Custo**:
- Input: $0.01 por 1K tokens
- Output: $0.03 por 1K tokens
- Exemplo: 1000 traduÃ§Ãµes/mÃªs â‰ˆ $50-100

**Obter chave**: https://platform.openai.com/api-keys

### Anthropic (Claude)

```python
config = LLMConfig.api(
    provider="anthropic",
    api_key="sk-ant-...",
    model="claude-3-opus"
)
```

**Custo**:
- Input: $0.015 por 1K tokens
- Output: $0.075 por 1K tokens

**Obter chave**: https://console.anthropic.com/

### Google (Gemini)

```python
config = LLMConfig.api(
    provider="google",
    api_key="AIza...",
    model="gemini-pro"
)
```

**Custo**:
- Input: $0.0005 por 1K tokens (mais barato!)
- Output: $0.0015 por 1K tokens

**Obter chave**: https://makersuite.google.com/app/apikey

### Cohere (Command)

```python
config = LLMConfig.api(
    provider="cohere",
    api_key="...",
    model="command"
)
```

**Custo**:
- Input: $0.001 por 1K tokens
- Output: $0.002 por 1K tokens

**Obter chave**: https://dashboard.cohere.com/api-keys

---

## ğŸ”„ OpÃ§Ã£o 3: HÃ­brido (Melhor Custo-BenefÃ­cio)

### EstratÃ©gia: Local para ProduÃ§Ã£o, API para Fallback

```python
from aethel.ai import AIGate, LLMConfig

# ConfiguraÃ§Ã£o primÃ¡ria (local)
primary_config = LLMConfig.local("ollama", "llama3")

# ConfiguraÃ§Ã£o fallback (API)
fallback_config = LLMConfig.api("openai", "sk-...", "gpt-4-turbo")

# AI-Gate com fallback automÃ¡tico
gate = AIGate(
    config=primary_config,
    fallback=fallback_config
)

# Se local falhar, usa API automaticamente
result = gate.voice_to_code("Transfer $100")
```

### Vantagens
âœ… **Custo otimizado** (90% local, 10% API)  
âœ… **Alta disponibilidade** (fallback automÃ¡tico)  
âœ… **Qualidade garantida** (API para casos complexos)  
âœ… **Privacidade** (dados sensÃ­veis ficam local)

---

## ğŸ’° ComparaÃ§Ã£o de Custos

### CenÃ¡rio: 10.000 traduÃ§Ãµes/mÃªs

| OpÃ§Ã£o | Custo Mensal | Custo Anual | Privacidade |
|-------|--------------|-------------|-------------|
| **Ollama Local** | $0 | $0 | 100% |
| **OpenAI GPT-4** | $500-1000 | $6K-12K | Depende |
| **Google Gemini** | $50-100 | $600-1.2K | Depende |
| **HÃ­brido (90% local)** | $50-100 | $600-1.2K | 90% |

### RecomendaÃ§Ã£o por Tipo de Cliente

**Startups/Desenvolvimento**:
- Use: Google Gemini ou Cohere
- Custo: ~$100/mÃªs
- RÃ¡pido para comeÃ§ar

**Empresas MÃ©dias**:
- Use: HÃ­brido (Ollama + OpenAI)
- Custo: ~$200/mÃªs
- Balanceado

**Bancos/Governo**:
- Use: Ollama Local (100%)
- Custo: $0/mÃªs (apenas hardware)
- Privacidade total

---

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### MÃºltiplos LLMs para Diferentes Tarefas

```python
from aethel.ai import AIGate, LLMConfig

# LLM rÃ¡pido para traduÃ§Ãµes simples
fast_config = LLMConfig.local("ollama", "llama3")

# LLM poderoso para cÃ³digo complexo
powerful_config = LLMConfig.api("openai", "sk-...", "gpt-4-turbo")

# Configurar AI-Gate com roteamento inteligente
gate = AIGate(
    config=fast_config,
    complex_config=powerful_config,
    auto_route=True  # Escolhe automaticamente
)
```

### Monitoramento de Custos

```python
# Rastrear custos em tempo real
gate = AIGate(config=api_config, track_costs=True)

# Usar
result = gate.voice_to_code("Transfer $100")

# Ver custos
stats = gate.get_statistics()
print(f"Total cost: ${stats['total_cost']:.4f}")
print(f"Tokens used: {stats['total_tokens']}")
```

### Rate Limiting

```python
# Limitar uso para controlar custos
gate = AIGate(
    config=api_config,
    max_requests_per_minute=60,
    max_cost_per_day=10.0  # $10/dia mÃ¡ximo
)
```

---

## ğŸ¯ Modelo de NegÃ³cio para DIOTEC 360

### OpÃ§Ã£o A: Cliente Traz PrÃ³prio LLM (BYOL)

**PreÃ§o**: $500/mÃªs (plataforma Aethel)

**Inclui**:
- Acesso Ã  plataforma Aethel
- VerificaÃ§Ã£o matemÃ¡tica ilimitada
- Suporte tÃ©cnico
- AtualizaÃ§Ãµes

**Cliente fornece**:
- PrÃ³prio LLM (Ollama, etc.)
- Infraestrutura

**Margem**: 100% (sem custo de API)

---

### OpÃ§Ã£o B: Managed AI (VocÃª Fornece LLM)

**Tier 1: Basic**
- PreÃ§o: $1,500/mÃªs
- Inclui: 10K tokens GPT-4/mÃªs
- Seu custo: ~$300 (OpenAI)
- **Sua margem: $1,200/mÃªs**

**Tier 2: Professional**
- PreÃ§o: $5,000/mÃªs
- Inclui: 100K tokens GPT-4/mÃªs
- Seu custo: ~$1,000
- **Sua margem: $4,000/mÃªs**

**Tier 3: Enterprise**
- PreÃ§o: $50,000/mÃªs
- Inclui: Ilimitado (hÃ­brido)
- Seu custo: ~$5,000
- **Sua margem: $45,000/mÃªs**

---

### OpÃ§Ã£o C: HÃ­brido (Recomendado)

**PreÃ§o Base**: $1,000/mÃªs (plataforma)

**Add-ons**:
- +$500/mÃªs: Managed AI (10K tokens)
- +$2,000/mÃªs: Managed AI (100K tokens)
- +$5,000/mÃªs: Managed AI (ilimitado)

**Flexibilidade**: Cliente escolhe quando usar local vs API

---

## ğŸ“Š ProjeÃ§Ã£o de Receita

### CenÃ¡rio Conservador (50 clientes)

**Mix de clientes**:
- 20 clientes BYOL: 20 Ã— $500 = $10K/mÃªs
- 20 clientes Basic: 20 Ã— $1,500 = $30K/mÃªs
- 8 clientes Pro: 8 Ã— $5,000 = $40K/mÃªs
- 2 clientes Enterprise: 2 Ã— $50,000 = $100K/mÃªs

**Total**: $180K/mÃªs = **$2.16M/ano**

**Seus custos de API**: ~$30K/ano

**Lucro lÃ­quido**: **$2.13M/ano**

---

## ğŸš€ PrÃ³ximos Passos

### Para ComeÃ§ar Agora

1. **Instalar Ollama** (5 minutos)
2. **Baixar Llama 3** (10 minutos)
3. **Testar AI-Gate** (5 minutos)
4. **Criar conta PayPal Business** (10 minutos)
5. **LanÃ§ar site diotec360.com** (1 dia)

### Para Escalar

1. **Documentar casos de uso** (1 semana)
2. **Criar demos** (1 semana)
3. **Pilotos com 5 clientes** (1 mÃªs)
4. **LanÃ§amento comercial** (2 meses)

---

## ğŸ“ Suporte

**DocumentaÃ§Ã£o**: https://docs.diotec360.com  
**Email**: support@diotec360.com  
**Discord**: https://discord.gg/aethel

---

**[STATUS: LLM SETUP GUIDE COMPLETE]**  
**[NEXT: INSTALL OLLAMA AND TEST]**  
**[VERDICT: READY FOR PRODUCTION]**

ğŸ§ â˜ï¸ğŸ ğŸ’°ğŸš€
